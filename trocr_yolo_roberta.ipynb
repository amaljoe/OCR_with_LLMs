{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T11:57:52.176093Z",
     "start_time": "2024-11-26T11:57:13.777939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pycparser.ply.yacc import token\n",
    "from ultralytics import YOLO\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel, AutoModelForCausalLM, pipeline, AutoModelForMaskedLM\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.translate import bleu_score\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "import torch\n",
    "\n",
    "yolo_weights_path = \"final_wts.pt\"\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "\n",
    "processor = TrOCRProcessor.from_pretrained('microsoft/trocr-large-handwritten')\n",
    "trocr_model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-large-handwritten').to(device)\n",
    "trocr_model.config.num_beams = 1\n",
    "\n",
    "yolo_model = YOLO(yolo_weights_path).to('mps')\n",
    "unmasker_large = pipeline('fill-mask', model='roberta-large', device=device)\n",
    "roberta_model = AutoModelForMaskedLM.from_pretrained(\"roberta-large\").to(device)\n",
    "\n",
    "print(f'TrOCR and YOLO Models loaded on {device}')"
   ],
   "id": "b9b59ee859304070",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config of the encoder: <class 'transformers.models.vit.modeling_vit.ViTModel'> is overwritten by shared encoder config: ViTConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"encoder_stride\": 16,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"image_size\": 384,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"vit\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"patch_size\": 16,\n",
      "  \"qkv_bias\": false,\n",
      "  \"transformers_version\": \"4.46.2\"\n",
      "}\n",
      "\n",
      "Config of the decoder: <class 'transformers.models.trocr.modeling_trocr.TrOCRForCausalLM'> is overwritten by shared decoder config: TrOCRConfig {\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_cross_attention\": true,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"cross_attention_hidden_size\": 1024,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_decoder\": true,\n",
      "  \"layernorm_embedding\": true,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"trocr\",\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"transformers_version\": \"4.46.2\",\n",
      "  \"use_cache\": false,\n",
      "  \"use_learned_position_embeddings\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-large-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrOCR and YOLO Models loaded on mps\n"
     ]
    }
   ],
   "execution_count": 224
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T12:28:10.138403Z",
     "start_time": "2024-11-26T12:28:03.767418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "CONFIDENCE_THRESHOLD = 0.72\n",
    "BLEU_THRESHOLD = 0.6\n",
    "\n",
    "\n",
    "def inference(image_path, debug=False, return_texts='final'):\n",
    "    def get_cropped_images(image_path):\n",
    "        results = yolo_model(image_path, save=True)\n",
    "        patches = []\n",
    "        ys = []\n",
    "        for box in sorted(results[0].boxes, key=lambda x: x.xywh[0][1]):\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "            x_center, y_center, w, h  = box.xywh[0].cpu().numpy()\n",
    "            x, y = x_center - w / 2, y_center - h / 2\n",
    "            cropped_image = image.crop((x, y, x + w, y + h))\n",
    "            patches.append(cropped_image)\n",
    "            ys.append(y)\n",
    "        bounding_box_path = results[0].save_dir + results[0].path[results[0].path.rindex('/'):-4] + '.jpg'\n",
    "        return patches, ys, bounding_box_path\n",
    "\n",
    "    def get_model_output(images):\n",
    "        pixel_values = processor(images=images, return_tensors=\"pt\").pixel_values.to(device)\n",
    "        output = trocr_model.generate(pixel_values, return_dict_in_generate=True, output_logits=True, max_new_tokens=30)\n",
    "        generated_texts = processor.batch_decode(output.sequences, skip_special_tokens=True)\n",
    "        generated_tokens = [processor.tokenizer.convert_ids_to_tokens(seq) for seq in output.sequences]\n",
    "        stacked_logits = torch.stack(output.logits, dim=1)\n",
    "        return generated_texts, stacked_logits, generated_tokens\n",
    "\n",
    "    def get_scores(logits):\n",
    "        scores = logits.softmax(-1).max(-1).values.mean(-1)\n",
    "        return scores\n",
    "\n",
    "    def post_process_texts(generated_texts):\n",
    "        for i in range(len(generated_texts)):\n",
    "            if len(generated_texts[i]) > 2 and generated_texts[i][:2] == '# ':\n",
    "                generated_texts[i] = generated_texts[i][2:]\n",
    "                \n",
    "            if len(generated_texts[i]) > 2 and generated_texts[i][-2:] == ' #':\n",
    "                generated_texts[i] = generated_texts[i][:-2]\n",
    "        return generated_texts\n",
    "\n",
    "    def get_qualified_texts(generated_texts, scores, y, logits, tokens):\n",
    "        qualified_texts = []\n",
    "        for text, score, y_i, logits_i, tokens_i in zip(generated_texts, scores, y, logits, tokens):\n",
    "            if score > CONFIDENCE_THRESHOLD:\n",
    "                qualified_texts.append({\n",
    "                    'text': text,\n",
    "                    'score': score,\n",
    "                    'y': y_i,\n",
    "                    'logits': logits_i,\n",
    "                    'tokens': tokens_i\n",
    "                })\n",
    "        return qualified_texts\n",
    "\n",
    "    def get_adjacent_bleu_scores(qualified_texts):\n",
    "        def get_bleu_score(hypothesis, references):\n",
    "            weights = [0.5, 0.5]\n",
    "            smoothing = SmoothingFunction()\n",
    "            return bleu_score.sentence_bleu(references, hypothesis, weights=weights,\n",
    "                                            smoothing_function=smoothing.method1)\n",
    "\n",
    "        for i in range(len(qualified_texts)):\n",
    "            hyp = qualified_texts[i]['text'].split()\n",
    "            bleu = 0\n",
    "            if i < len(qualified_texts) - 1:\n",
    "                ref = qualified_texts[i + 1]['text'].split()\n",
    "                bleu = get_bleu_score(hyp, [ref])\n",
    "            qualified_texts[i]['bleu'] = bleu\n",
    "        return qualified_texts\n",
    "\n",
    "    def remove_overlapping_texts(qualified_texts):\n",
    "        final_texts = []\n",
    "        new = True\n",
    "        for i in range(len(qualified_texts)):\n",
    "            if new:\n",
    "                final_texts.append(qualified_texts[i])\n",
    "            else:\n",
    "                if final_texts[-1]['score'] < qualified_texts[i]['score']:\n",
    "                    final_texts[-1] = qualified_texts[i]\n",
    "            new = qualified_texts[i]['bleu'] < BLEU_THRESHOLD\n",
    "        return final_texts\n",
    "\n",
    "    cropped_images, y, bounding_box_path = get_cropped_images(image_path)\n",
    "    if debug:\n",
    "        print('Number of cropped images:', len(cropped_images))\n",
    "    generated_texts, logits, gen_tokens = get_model_output(cropped_images)\n",
    "    normalised_scores = get_scores(logits)\n",
    "    if return_texts == 'generated':\n",
    "        return pd.DataFrame({\n",
    "            'text': generated_texts,\n",
    "            'score': normalised_scores,\n",
    "            'y': y,\n",
    "        })\n",
    "    generated_texts = post_process_texts(generated_texts)\n",
    "    if return_texts == 'post_processed':\n",
    "        return pd.DataFrame({\n",
    "            'text': generated_texts,\n",
    "            'score': normalised_scores,\n",
    "            'y': y\n",
    "        })\n",
    "    qualified_texts = get_qualified_texts(generated_texts, normalised_scores, y, logits, gen_tokens)\n",
    "    if return_texts == 'qualified':\n",
    "        return pd.DataFrame(qualified_texts)\n",
    "    qualified_texts = get_adjacent_bleu_scores(qualified_texts)\n",
    "    if return_texts == 'qualified_with_bleu':\n",
    "        return pd.DataFrame(qualified_texts)\n",
    "    final_texts = remove_overlapping_texts(qualified_texts)\n",
    "    final_texts_df = pd.DataFrame(final_texts, columns=['text', 'score', 'y'])\n",
    "    final_tokens = [text['tokens'] for text in final_texts]\n",
    "    final_logits = [text['logits'] for text in final_texts]\n",
    "    if return_texts == 'final':\n",
    "        return final_texts_df\n",
    "    \n",
    "    return final_texts_df, bounding_box_path, final_tokens, final_logits\n",
    "\n",
    "\n",
    "image_path = \"raw_dataset/g06-037h.png\"\n",
    "df, bounding_path, tokens, logits = inference(image_path, debug=False, return_texts='final_v2')\n",
    "df"
   ],
   "id": "756864428125bf03",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/amaljoe/Desktop/Workspace/IITB/NLP/OCR_with_LLMs/raw_dataset/g06-037h.png: 576x640 14 handwritten_lines, 487.1ms\n",
      "Speed: 36.3ms preprocess, 487.1ms inference, 10.2ms postprocess per image at shape (1, 3, 576, 640)\n",
      "Results saved to \u001B[1m/Users/amaljoe/Desktop/Workspace/IITB/NLP/OCR_with_LLMs/runs/detect/predict36\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                                            text  \\\n",
       "0            God grant , however , that I may be a false prophet   \n",
       "1                       & that all may go well . Sir R. Peel was   \n",
       "2              here , I understand , but an express task him off   \n",
       "3                                                  Yesterday . '   \n",
       "4                  While he was in Naples there had opened a new   \n",
       "5                 chapter in the history of Anglesey's unceasing   \n",
       "6             search for an effective alleviation of his painful   \n",
       "7                 absolutely . None of the numerous conventional   \n",
       "8                to remedies to which he had been subjected ever   \n",
       "9                      Since the symptoms had first shown them -   \n",
       "10  server seventeen years before had had the slightest effect .   \n",
       "\n",
       "                             score            y  \n",
       "0   tensor(0.9806, device='mps:0')    82.707489  \n",
       "1   tensor(0.9002, device='mps:0')   267.147385  \n",
       "2   tensor(0.8848, device='mps:0')   436.745956  \n",
       "3   tensor(0.8136, device='mps:0')   610.187439  \n",
       "4   tensor(0.9930, device='mps:0')   792.057220  \n",
       "5   tensor(0.9791, device='mps:0')   994.093018  \n",
       "6   tensor(0.9445, device='mps:0')  1147.620361  \n",
       "7   tensor(0.9200, device='mps:0')  1330.609741  \n",
       "8   tensor(0.9066, device='mps:0')  1513.878235  \n",
       "9   tensor(0.9270, device='mps:0')  1678.105103  \n",
       "10  tensor(0.8859, device='mps:0')  1848.774353  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>God grant , however , that I may be a false prophet</td>\n",
       "      <td>tensor(0.9806, device='mps:0')</td>\n",
       "      <td>82.707489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&amp; that all may go well . Sir R. Peel was</td>\n",
       "      <td>tensor(0.9002, device='mps:0')</td>\n",
       "      <td>267.147385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>here , I understand , but an express task him off</td>\n",
       "      <td>tensor(0.8848, device='mps:0')</td>\n",
       "      <td>436.745956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yesterday . '</td>\n",
       "      <td>tensor(0.8136, device='mps:0')</td>\n",
       "      <td>610.187439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>While he was in Naples there had opened a new</td>\n",
       "      <td>tensor(0.9930, device='mps:0')</td>\n",
       "      <td>792.057220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>chapter in the history of Anglesey's unceasing</td>\n",
       "      <td>tensor(0.9791, device='mps:0')</td>\n",
       "      <td>994.093018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>search for an effective alleviation of his painful</td>\n",
       "      <td>tensor(0.9445, device='mps:0')</td>\n",
       "      <td>1147.620361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>absolutely . None of the numerous conventional</td>\n",
       "      <td>tensor(0.9200, device='mps:0')</td>\n",
       "      <td>1330.609741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>to remedies to which he had been subjected ever</td>\n",
       "      <td>tensor(0.9066, device='mps:0')</td>\n",
       "      <td>1513.878235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Since the symptoms had first shown them -</td>\n",
       "      <td>tensor(0.9270, device='mps:0')</td>\n",
       "      <td>1678.105103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>server seventeen years before had had the slightest effect .</td>\n",
       "      <td>tensor(0.8859, device='mps:0')</td>\n",
       "      <td>1848.774353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 268
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T12:27:28.744113Z",
     "start_time": "2024-11-26T12:27:28.524933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_new_logits(tokens):\n",
    "    inputs = tokens.reshape(1, -1)\n",
    "    # Get the logits from the model\n",
    "    with torch.no_grad():\n",
    "        outputs = roberta_model(input_ids=inputs, attention_mask=torch.ones(inputs.shape).to(device))\n",
    "        logits = outputs.logits\n",
    "\n",
    "\n",
    "    logits_flattened = logits.reshape(-1, slogits.shape[-1])\n",
    "    print(processor.batch_decode([logits_flattened.argmax(-1)], skip_special_tokens=True))\n",
    "    return logits.reshape(tokens.shape + (logits.shape[-1],))\n",
    "\n",
    "\n",
    "slogits = torch.stack([logit for logit in logits], dim=0)\n",
    "tokens = slogits.argmax(-1)\n",
    "confidence = slogits.softmax(-1).max(-1).values\n",
    "indices = torch.where(confidence < 0.5)\n",
    "# put 50264(mask) when confidence < 0.5\n",
    "for i, j in zip(indices[0], indices[1]):\n",
    "    if i != 6:\n",
    "        continue\n",
    "    tokens[i, j] = torch.tensor(50264)\n",
    "\n",
    "new_logits = get_new_logits(tokens)"
   ],
   "id": "a49fb903d7476922",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"# , however , that I may be a false prophet# & that all may go well . Sir R. Peel washere , I understand , but an express carried him offhere . 'While he was in Naples there had opened a newchapter in. history of Anglesey's unceasingsearch for an effective alleviation of his pain.effects . None of the numerousto remedies to which he had been subjectedSince the symptoms had first shown themselves -# - seventeen years before had had the slightest effect .\"]\n"
     ]
    }
   ],
   "execution_count": 267
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T12:21:16.825782Z",
     "start_time": "2024-11-26T12:21:16.736550Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i, j in zip(indices[0], indices[1]):\n",
    "    slogits[i, j] = slogits[i, j] * 0.5 + new_logits[i, j] * 0.5\n",
    "\n",
    "logits_flattened = slogits.reshape(-1, slogits.shape[-1])\n",
    "processor.batch_decode([logits_flattened.argmax(-1)], skip_special_tokens=True)"
   ],
   "id": "b0a43a74184b7bd1",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"God grant , however , that I may be a false prophet# and that all may go well . Sir R. Peel was# , I understand , but an express task him offand . 'While he was in Naples there had opened a newchapter in the history of Anglesey's unceasingsearch for an effective alleviation of his painful# . None of the numerous conventionalmedical remedies to which he had been subjected eversince the symptoms had first shown them -#. seventeen years before had had the slightest effect .\"]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 250
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T11:40:21.300455Z",
     "start_time": "2024-11-26T11:40:21.297405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "processor.tokenizer.encode(\"\")\n",
    "processor.tokenizer.decode([0, 0])"
   ],
   "id": "dfca1aee81eb5bd3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s><s>'"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 208
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T11:07:42.192649Z",
     "start_time": "2024-11-26T11:07:38.636018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_cropped_images(image_path):\n",
    "    results = yolo_model(image_path, save=True)\n",
    "    patches = []\n",
    "    ys = []\n",
    "    for box in sorted(results[0].boxes, key=lambda x: x.xywh[0][1]):\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        x_center, y_center, w, h  = box.xywh[0].cpu().numpy()\n",
    "        x, y = x_center - w / 2, y_center - h / 2\n",
    "        cropped_image = image.crop((x, y, x + w, y + h))\n",
    "        patches.append(cropped_image)\n",
    "        ys.append(y)\n",
    "    bounding_box_path = results[0].save_dir + results[0].path[results[0].path.rindex('/'):-4] + '.jpg'\n",
    "    return patches, ys, bounding_box_path\n",
    "\n",
    "def get_model_output(images):\n",
    "    pixel_values = processor(images=images, return_tensors=\"pt\").pixel_values.to(device)\n",
    "    output = trocr_model.generate(pixel_values, return_dict_in_generate=True, output_logits=True, max_new_tokens=30)\n",
    "    generated_texts = processor.batch_decode(output.sequences, skip_special_tokens=True)\n",
    "    generated_tokens = [processor.tokenizer.convert_ids_to_tokens(seq) for seq in output.sequences]\n",
    "    logits = torch.stack(output.logits, dim=1)\n",
    "    return generated_texts, logits, generated_tokens\n",
    "\n",
    "\n",
    "image_path = \"data/FML_whiteboard2.png\"\n",
    "cropped_images, y, bounding_box_path = get_cropped_images(image_path)\n",
    "generated_texts, logits, gen_tokens = get_model_output(cropped_images)\n",
    "for i in range(len(generated_texts)):\n",
    "    print(generated_texts[i], logits[i].softmax(-1).max(-1).values.mean())"
   ],
   "id": "5d394c6596881fc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/amaljoe/Desktop/Workspace/IITB/NLP/OCR_with_LLMs/data/FML_whiteboard2.png: 384x640 8 handwritten_lines, 109.5ms\n",
      "Speed: 6.8ms preprocess, 109.5ms inference, 10.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1m/Users/amaljoe/Desktop/Workspace/IITB/NLP/OCR_with_LLMs/runs/detect/predict34\u001B[0m\n",
      "K-means clustering algorithm tensor(0.9335, device='mps:0')\n",
      "Assume we have K clusters of points ; each point in a cluster . tensor(0.9584, device='mps:0')\n",
      "Assume we have K clusters of points ; each point in a cluster . tensor(0.9604, device='mps:0')\n",
      "is closest to its centroid ( more than any other cluster centroid ) tensor(0.9554, device='mps:0')\n",
      "If cluster assignment is known , it is easy to compute the centriots . tensor(0.9374, device='mps:0')\n",
      "It cluster assignment is known , it is easy to compute the centroids . tensor(0.9117, device='mps:0')\n",
      "If cluster centrids are known , it is easy to do cluster assignment . tensor(0.8591, device='mps:0')\n",
      "How do we solve this chicken-egg problem ? Fix one , optimize the other ! tensor(0.9381, device='mps:0')\n"
     ]
    }
   ],
   "execution_count": 172
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T10:14:28.910705Z",
     "start_time": "2024-11-26T10:14:28.907458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_scores(logits):\n",
    "    stacked_logits = torch.stack(logits, dim=1)\n",
    "    scores = stacked_logits.softmax(-1).max(-1).values.mean(-1)\n",
    "    return scores\n",
    "\n",
    "get_scores(logits).shape"
   ],
   "id": "44e70b51f29bb02a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 122
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T10:48:39.346081Z",
     "start_time": "2024-11-26T10:48:39.342047Z"
    }
   },
   "cell_type": "code",
   "source": "generated_texts",
   "id": "19ad7c24c04a5aa5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['',\n",
       "  'K',\n",
       "  '-',\n",
       "  'me',\n",
       "  'ans',\n",
       "  ' clust',\n",
       "  'ering',\n",
       "  ' algorithm',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  ''],\n",
       " ['',\n",
       "  'Ass',\n",
       "  'ume',\n",
       "  ' we',\n",
       "  ' have',\n",
       "  ' K',\n",
       "  ' clusters',\n",
       "  ' of',\n",
       "  ' points',\n",
       "  ' ;',\n",
       "  ' each',\n",
       "  ' point',\n",
       "  ' in',\n",
       "  ' a',\n",
       "  ' cluster',\n",
       "  ' .',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  ''],\n",
       " ['',\n",
       "  'Ass',\n",
       "  'ume',\n",
       "  ' we',\n",
       "  ' have',\n",
       "  ' K',\n",
       "  ' clusters',\n",
       "  ' of',\n",
       "  ' points',\n",
       "  ' ;',\n",
       "  ' each',\n",
       "  ' point',\n",
       "  ' in',\n",
       "  ' a',\n",
       "  ' cluster',\n",
       "  ' .',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  ''],\n",
       " ['',\n",
       "  'is',\n",
       "  ' closest',\n",
       "  ' to',\n",
       "  ' its',\n",
       "  ' cent',\n",
       "  'roid',\n",
       "  ' (',\n",
       "  ' more',\n",
       "  ' than',\n",
       "  ' any',\n",
       "  ' other',\n",
       "  ' cluster',\n",
       "  ' cent',\n",
       "  'roid',\n",
       "  ' )',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  ''],\n",
       " ['',\n",
       "  'If',\n",
       "  ' cluster',\n",
       "  ' assignment',\n",
       "  ' is',\n",
       "  ' known',\n",
       "  ' ,',\n",
       "  ' it',\n",
       "  ' is',\n",
       "  ' easy',\n",
       "  ' to',\n",
       "  ' compute',\n",
       "  ' the',\n",
       "  ' cent',\n",
       "  'riots',\n",
       "  ' .',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  ''],\n",
       " ['',\n",
       "  'It',\n",
       "  ' cluster',\n",
       "  ' assignment',\n",
       "  ' is',\n",
       "  ' known',\n",
       "  ' ,',\n",
       "  ' it',\n",
       "  ' is',\n",
       "  ' easy',\n",
       "  ' to',\n",
       "  ' compute',\n",
       "  ' the',\n",
       "  ' cent',\n",
       "  'ro',\n",
       "  'ids',\n",
       "  ' .',\n",
       "  '',\n",
       "  '',\n",
       "  ''],\n",
       " ['',\n",
       "  'If',\n",
       "  ' cluster',\n",
       "  ' cent',\n",
       "  'r',\n",
       "  'ids',\n",
       "  ' are',\n",
       "  ' known',\n",
       "  ' ,',\n",
       "  ' it',\n",
       "  ' is',\n",
       "  ' easy',\n",
       "  ' to',\n",
       "  ' do',\n",
       "  ' cluster',\n",
       "  ' assignment',\n",
       "  ' .',\n",
       "  '',\n",
       "  '',\n",
       "  ''],\n",
       " ['',\n",
       "  'How',\n",
       "  ' do',\n",
       "  ' we',\n",
       "  ' solve',\n",
       "  ' this',\n",
       "  ' ch',\n",
       "  'icken',\n",
       "  '-',\n",
       "  'egg',\n",
       "  ' problem',\n",
       "  ' ?',\n",
       "  ' Fix',\n",
       "  ' one',\n",
       "  ' ,',\n",
       "  ' optimize',\n",
       "  ' the',\n",
       "  ' other',\n",
       "  ' !',\n",
       "  '']]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 155
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T10:26:09.260826Z",
     "start_time": "2024-11-26T10:26:09.257116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = \" \".join(generated_texts)\n",
    "text"
   ],
   "id": "9a919cc67c67d8da",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'K-means clustering algorithm Assume we have K clusters of points ; each point in a cluster . Assume we have K clusters of points ; each point in a cluster . is closest to its centroid ( more than any other cluster centroid ) If cluster assignment is known , it is easy to compute the centriots . It cluster assignment is known , it is easy to compute the centroids . If cluster centrids are known , it is easy to do cluster assignment . How do we solve this chicken-egg problem ? Fix one , optimize the other !'"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 146
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T10:53:21.648001Z",
     "start_time": "2024-11-26T10:53:21.592948Z"
    }
   },
   "cell_type": "code",
   "source": [
    "confidence = logits.softmax(-1).max(-1).values\n",
    "mask_indices = torch.where(confidence < 0.5)\n",
    "\n",
    "for y, x in zip(mask_indices[0], mask_indices[1]):\n",
    "    for i in range(x, )"
   ],
   "id": "88b148aee13c10",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " cent\n",
      " cent\n",
      "riots\n",
      " .\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[162], line 9\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(index[\u001B[38;5;241m1\u001B[39m], \u001B[38;5;28mlen\u001B[39m(line)):\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;28mprint\u001B[39m(line[i])\n\u001B[0;32m----> 9\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mgenerated_texts\u001B[49m\u001B[43m[\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m     10\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[0;31mIndexError\u001B[0m: string index out of range"
     ]
    }
   ],
   "execution_count": 162
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T09:24:15.002355Z",
     "start_time": "2024-11-26T09:24:14.887449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "stacked_logits = torch.stack(logits, dim=1)\n",
    "processor.batch_decode([stacked_logits[-2].argmax(-1)[:5]], skip_special_tokens=True)"
   ],
   "id": "9539651d8f9a9e22",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['If cluster centrids']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T09:17:50.578637Z",
     "start_time": "2024-11-26T09:17:50.502586Z"
    }
   },
   "cell_type": "code",
   "source": "stacked_logits[-2].softmax(-1).max(-1)",
   "id": "4bab4daee1ab1cba",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([0.5884, 0.9979, 0.3797, 0.8033, 0.7809, 1.0000, 1.0000, 0.9999, 0.9997, 1.0000, 0.9999, 0.9966, 0.9997, 0.2181, 0.9184, 0.6810, 0.9987, 0.9935, 0.9677], device='mps:0'),\n",
       "indices=tensor([ 1106, 18016,   715,   338,  7823,    32,   684,  2156,    24,    16,  1365,     7,   109, 18016, 11717,   479,     2,     2,     2], device='mps:0'))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T09:50:39.424133Z",
     "start_time": "2024-11-26T09:50:39.294794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res = unmasker_large(\"\"\"K Means clustering algorithm\n",
    "Assume we have K cluster of points; each point in a cluster\n",
    "Is closest to its centroid (more than any other cluster centroid)\n",
    "If cluster assignment is known, it is easy to compute the centroid\n",
    "If cluster <mask> is known, it is easy to do cluster assignment\n",
    "How do we solve this chicken-egg problem? Fix one, optimize the other!\"\"\", top_k=10)\n",
    "res"
   ],
   "id": "e9bceaa80177d260",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.31558406352996826,\n",
       "  'token': 11717,\n",
       "  'token_str': ' assignment',\n",
       "  'sequence': 'K Means clustering algorithm\\nAssume we have K cluster of points; each point in a cluster\\nIs closest to its centroid (more than any other cluster centroid)\\nIf cluster assignment is known, it is easy to compute the centroid\\nIf cluster assignment is known, it is easy to do cluster assignment\\nHow do we solve this chicken-egg problem? Fix one, optimize the other!'},\n",
       " {'score': 0.06008317694067955,\n",
       "  'token': 15229,\n",
       "  'token_str': ' composition',\n",
       "  'sequence': 'K Means clustering algorithm\\nAssume we have K cluster of points; each point in a cluster\\nIs closest to its centroid (more than any other cluster centroid)\\nIf cluster assignment is known, it is easy to compute the centroid\\nIf cluster composition is known, it is easy to do cluster assignment\\nHow do we solve this chicken-egg problem? Fix one, optimize the other!'},\n",
       " {'score': 0.03243965655565262,\n",
       "  'token': 22432,\n",
       "  'token_str': ' alignment',\n",
       "  'sequence': 'K Means clustering algorithm\\nAssume we have K cluster of points; each point in a cluster\\nIs closest to its centroid (more than any other cluster centroid)\\nIf cluster assignment is known, it is easy to compute the centroid\\nIf cluster alignment is known, it is easy to do cluster assignment\\nHow do we solve this chicken-egg problem? Fix one, optimize the other!'},\n",
       " {'score': 0.028971761465072632,\n",
       "  'token': 1836,\n",
       "  'token_str': ' size',\n",
       "  'sequence': 'K Means clustering algorithm\\nAssume we have K cluster of points; each point in a cluster\\nIs closest to its centroid (more than any other cluster centroid)\\nIf cluster assignment is known, it is easy to compute the centroid\\nIf cluster size is known, it is easy to do cluster assignment\\nHow do we solve this chicken-egg problem? Fix one, optimize the other!'},\n",
       " {'score': 0.024425722658634186,\n",
       "  'token': 3599,\n",
       "  'token_str': ' identity',\n",
       "  'sequence': 'K Means clustering algorithm\\nAssume we have K cluster of points; each point in a cluster\\nIs closest to its centroid (more than any other cluster centroid)\\nIf cluster assignment is known, it is easy to compute the centroid\\nIf cluster identity is known, it is easy to do cluster assignment\\nHow do we solve this chicken-egg problem? Fix one, optimize the other!'},\n",
       " {'score': 0.018887916579842567,\n",
       "  'token': 2259,\n",
       "  'token_str': ' location',\n",
       "  'sequence': 'K Means clustering algorithm\\nAssume we have K cluster of points; each point in a cluster\\nIs closest to its centroid (more than any other cluster centroid)\\nIf cluster assignment is known, it is easy to compute the centroid\\nIf cluster location is known, it is easy to do cluster assignment\\nHow do we solve this chicken-egg problem? Fix one, optimize the other!'},\n",
       " {'score': 0.016024157404899597,\n",
       "  'token': 12278,\n",
       "  'token_str': ' allocation',\n",
       "  'sequence': 'K Means clustering algorithm\\nAssume we have K cluster of points; each point in a cluster\\nIs closest to its centroid (more than any other cluster centroid)\\nIf cluster assignment is known, it is easy to compute the centroid\\nIf cluster allocation is known, it is easy to do cluster assignment\\nHow do we solve this chicken-egg problem? Fix one, optimize the other!'},\n",
       " {'score': 0.014906616881489754,\n",
       "  'token': 3184,\n",
       "  'token_str': ' structure',\n",
       "  'sequence': 'K Means clustering algorithm\\nAssume we have K cluster of points; each point in a cluster\\nIs closest to its centroid (more than any other cluster centroid)\\nIf cluster assignment is known, it is easy to compute the centroid\\nIf cluster structure is known, it is easy to do cluster assignment\\nHow do we solve this chicken-egg problem? Fix one, optimize the other!'},\n",
       " {'score': 0.013791101053357124,\n",
       "  'token': 14497,\n",
       "  'token_str': ' orientation',\n",
       "  'sequence': 'K Means clustering algorithm\\nAssume we have K cluster of points; each point in a cluster\\nIs closest to its centroid (more than any other cluster centroid)\\nIf cluster assignment is known, it is easy to compute the centroid\\nIf cluster orientation is known, it is easy to do cluster assignment\\nHow do we solve this chicken-egg problem? Fix one, optimize the other!'},\n",
       " {'score': 0.013612503185868263,\n",
       "  'token': 3854,\n",
       "  'token_str': ' distribution',\n",
       "  'sequence': 'K Means clustering algorithm\\nAssume we have K cluster of points; each point in a cluster\\nIs closest to its centroid (more than any other cluster centroid)\\nIf cluster assignment is known, it is easy to compute the centroid\\nIf cluster distribution is known, it is easy to do cluster assignment\\nHow do we solve this chicken-egg problem? Fix one, optimize the other!'}]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 117
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T09:40:12.049891Z",
     "start_time": "2024-11-26T09:40:11.455921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cluster_pred = stacked_logits[-2].softmax(-1)[2]\n",
    "res = unmasker_large(\"\"\"K Means clustering algorithm\n",
    "Assume we have K cluster of points; each point in a cluster\n",
    "Is closest to its centroid (more than any other cluster centroid)\n",
    "If cluster assignment is known, it is easy to compute the centroid\n",
    "If cluster <mask> is known, it is easy to do cluster assignment\"\"\")\n",
    "\n",
    "\n",
    "for pred in res:\n",
    "    score, token, str = pred['score'], pred['token'], pred['token_str']\n",
    "    confidence = score + cluster_pred[token]\n",
    "    print(str, confidence, cluster_pred[token])"
   ],
   "id": "f1845790b97c90f0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " assignment tensor(0.7182, device='mps:0') tensor(6.8814e-10, device='mps:0')\n",
      " alignment tensor(0.0231, device='mps:0') tensor(2.5890e-10, device='mps:0')\n",
      " identity tensor(0.0183, device='mps:0') tensor(3.6747e-07, device='mps:0')\n",
      " composition tensor(0.0157, device='mps:0') tensor(2.2282e-07, device='mps:0')\n",
      " orientation tensor(0.0120, device='mps:0') tensor(1.8597e-07, device='mps:0')\n"
     ]
    }
   ],
   "execution_count": 110
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
