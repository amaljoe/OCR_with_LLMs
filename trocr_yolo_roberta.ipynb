{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T09:21:34.763753Z",
     "start_time": "2024-11-26T09:21:08.515287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pycparser.ply.yacc import token\n",
    "from ultralytics import YOLO\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel, AutoModelForCausalLM, pipeline\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.translate import bleu_score\n",
    "from nltk.translate.bleu_score import SmoothingFunction\n",
    "import torch\n",
    "\n",
    "yolo_weights_path = \"final_wts.pt\"\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "\n",
    "processor = TrOCRProcessor.from_pretrained('microsoft/trocr-large-handwritten')\n",
    "trocr_model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-large-handwritten').to(device)\n",
    "trocr_model.config.num_beams = 1\n",
    "\n",
    "yolo_model = YOLO(yolo_weights_path).to('mps')\n",
    "unmasker_large = pipeline('fill-mask', model='roberta-large', device=\"mps\")\n",
    "\n",
    "\n",
    "print(f'TrOCR and YOLO Models loaded on {device}')"
   ],
   "id": "b9b59ee859304070",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config of the encoder: <class 'transformers.models.vit.modeling_vit.ViTModel'> is overwritten by shared encoder config: ViTConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"encoder_stride\": 16,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"image_size\": 384,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"vit\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"patch_size\": 16,\n",
      "  \"qkv_bias\": false,\n",
      "  \"transformers_version\": \"4.46.2\"\n",
      "}\n",
      "\n",
      "Config of the decoder: <class 'transformers.models.trocr.modeling_trocr.TrOCRForCausalLM'> is overwritten by shared decoder config: TrOCRConfig {\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_cross_attention\": true,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"cross_attention_hidden_size\": 1024,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_decoder\": true,\n",
      "  \"layernorm_embedding\": true,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"trocr\",\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"transformers_version\": \"4.46.2\",\n",
      "  \"use_cache\": false,\n",
      "  \"use_learned_position_embeddings\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-large-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrOCR and YOLO Models loaded on mps\n"
     ]
    }
   ],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T08:52:21.533347Z",
     "start_time": "2024-11-26T08:52:14.556830Z"
    }
   },
   "cell_type": "code",
   "source": [
    "CONFIDENCE_THRESHOLD = 0.72\n",
    "BLEU_THRESHOLD = 0.6\n",
    "\n",
    "\n",
    "def inference(image_path, debug=False, return_texts='final'):\n",
    "    def get_cropped_images(image_path):\n",
    "        results = yolo_model(image_path, save=True)\n",
    "        patches = []\n",
    "        ys = []\n",
    "        for box in sorted(results[0].boxes, key=lambda x: x.xywh[0][1]):\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "            x_center, y_center, w, h  = box.xywh[0].cpu().numpy()\n",
    "            x, y = x_center - w / 2, y_center - h / 2\n",
    "            cropped_image = image.crop((x, y, x + w, y + h))\n",
    "            patches.append(cropped_image)\n",
    "            ys.append(y)\n",
    "        bounding_box_path = results[0].save_dir + results[0].path[results[0].path.rindex('/'):-4] + '.jpg'\n",
    "        return patches, ys, bounding_box_path\n",
    "        \n",
    "    def get_model_output(images):\n",
    "        pixel_values = processor(images=images, return_tensors=\"pt\").pixel_values.to(device)\n",
    "        output = trocr_model.generate(pixel_values, return_dict_in_generate=True, output_scores=True, max_new_tokens=30)\n",
    "        generated_texts = processor.batch_decode(output.sequences, skip_special_tokens=True)\n",
    "        return generated_texts, output.sequences_scores\n",
    "\n",
    "    def post_process_texts(generated_texts):\n",
    "        for i in range(len(generated_texts)):\n",
    "            if len(generated_texts[i]) > 2 and generated_texts[i][:2] == '# ':\n",
    "                generated_texts[i] = generated_texts[i][2:]\n",
    "                \n",
    "            if len(generated_texts[i]) > 2 and generated_texts[i][-2:] == ' #':\n",
    "                generated_texts[i] = generated_texts[i][:-2]\n",
    "        return generated_texts\n",
    "\n",
    "    def get_qualified_texts(generated_texts, scores, y):\n",
    "        qualified_texts = []\n",
    "        for text, score, y_i in zip(generated_texts, scores, y):\n",
    "            if score > CONFIDENCE_THRESHOLD:\n",
    "                qualified_texts.append({\n",
    "                    'text': text,\n",
    "                    'score': score,\n",
    "                    'y': y_i\n",
    "                })\n",
    "        return qualified_texts\n",
    "\n",
    "    def get_adjacent_bleu_scores(qualified_texts):\n",
    "        def get_bleu_score(hypothesis, references):\n",
    "            weights = [0.5, 0.5]\n",
    "            smoothing = SmoothingFunction()\n",
    "            return bleu_score.sentence_bleu(references, hypothesis, weights=weights,\n",
    "                                            smoothing_function=smoothing.method1)\n",
    "\n",
    "        for i in range(len(qualified_texts)):\n",
    "            hyp = qualified_texts[i]['text'].split()\n",
    "            bleu = 0\n",
    "            if i < len(qualified_texts) - 1:\n",
    "                ref = qualified_texts[i + 1]['text'].split()\n",
    "                bleu = get_bleu_score(hyp, [ref])\n",
    "            qualified_texts[i]['bleu'] = bleu\n",
    "        return qualified_texts\n",
    "\n",
    "    def remove_overlapping_texts(qualified_texts):\n",
    "        final_texts = []\n",
    "        new = True\n",
    "        for i in range(len(qualified_texts)):\n",
    "            if new:\n",
    "                final_texts.append(qualified_texts[i])\n",
    "            else:\n",
    "                if final_texts[-1]['score'] < qualified_texts[i]['score']:\n",
    "                    final_texts[-1] = qualified_texts[i]\n",
    "            new = qualified_texts[i]['bleu'] < BLEU_THRESHOLD\n",
    "        return final_texts\n",
    "\n",
    "    cropped_images, y, bounding_box_path = get_cropped_images(image_path)\n",
    "    if debug:\n",
    "        print('Number of cropped images:', len(cropped_images))\n",
    "    generated_texts, scores = get_model_output(cropped_images)\n",
    "    normalised_scores = np.exp(scores.to('cpu').numpy())\n",
    "    if return_texts == 'generated':\n",
    "        return pd.DataFrame({\n",
    "            'text': generated_texts,\n",
    "            'score': normalised_scores,\n",
    "            'y': y\n",
    "        })\n",
    "    generated_texts = post_process_texts(generated_texts)\n",
    "    if return_texts == 'post_processed':\n",
    "        return pd.DataFrame({\n",
    "            'text': generated_texts,\n",
    "            'score': normalised_scores,\n",
    "            'y': y\n",
    "        })\n",
    "    qualified_texts = get_qualified_texts(generated_texts, normalised_scores, y)\n",
    "    if return_texts == 'qualified':\n",
    "        return pd.DataFrame(qualified_texts)\n",
    "    qualified_texts = get_adjacent_bleu_scores(qualified_texts)\n",
    "    if return_texts == 'qualified_with_bleu':\n",
    "        return pd.DataFrame(qualified_texts)\n",
    "    final_texts = remove_overlapping_texts(qualified_texts)\n",
    "    final_texts_df = pd.DataFrame(final_texts, columns=['text', 'score', 'y'])\n",
    "    return final_texts_df, bounding_box_path\n",
    "\n",
    "\n",
    "image_path = \"data/FML_whiteboard2.png\"\n",
    "df, bounding_path = inference(image_path, debug=False, return_texts='final')\n",
    "df"
   ],
   "id": "756864428125bf03",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/amaljoe/Desktop/Workspace/IITB/NLP/OCR_with_LLMs/data/FML_whiteboard2.png: 384x640 8 handwritten_lines, 371.8ms\n",
      "Speed: 11.1ms preprocess, 371.8ms inference, 1153.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1m/Users/amaljoe/Desktop/Workspace/IITB/NLP/OCR_with_LLMs/runs/detect/predict33\u001B[0m\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GenerateEncoderDecoderOutput' object has no attribute 'sequences_scores'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 104\u001B[0m\n\u001B[1;32m    100\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m final_texts_df, bounding_box_path\n\u001B[1;32m    103\u001B[0m image_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata/FML_whiteboard2.png\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m--> 104\u001B[0m df, bounding_path \u001B[38;5;241m=\u001B[39m \u001B[43minference\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdebug\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_texts\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mfinal\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    105\u001B[0m df\n",
      "Cell \u001B[0;32mIn[2], line 77\u001B[0m, in \u001B[0;36minference\u001B[0;34m(image_path, debug, return_texts)\u001B[0m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m debug:\n\u001B[1;32m     76\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mNumber of cropped images:\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28mlen\u001B[39m(cropped_images))\n\u001B[0;32m---> 77\u001B[0m generated_texts, scores \u001B[38;5;241m=\u001B[39m \u001B[43mget_model_output\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcropped_images\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     78\u001B[0m normalised_scores \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mexp(scores\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39mnumpy())\n\u001B[1;32m     79\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m return_texts \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgenerated\u001B[39m\u001B[38;5;124m'\u001B[39m:\n",
      "Cell \u001B[0;32mIn[2], line 24\u001B[0m, in \u001B[0;36minference.<locals>.get_model_output\u001B[0;34m(images)\u001B[0m\n\u001B[1;32m     22\u001B[0m output \u001B[38;5;241m=\u001B[39m trocr_model\u001B[38;5;241m.\u001B[39mgenerate(pixel_values, return_dict_in_generate\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, output_scores\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, max_new_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m30\u001B[39m)\n\u001B[1;32m     23\u001B[0m generated_texts \u001B[38;5;241m=\u001B[39m processor\u001B[38;5;241m.\u001B[39mbatch_decode(output\u001B[38;5;241m.\u001B[39msequences, skip_special_tokens\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m---> 24\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m generated_texts, \u001B[43moutput\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msequences_scores\u001B[49m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'GenerateEncoderDecoderOutput' object has no attribute 'sequences_scores'"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T09:23:02.197322Z",
     "start_time": "2024-11-26T09:22:59.431625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_cropped_images(image_path):\n",
    "    results = yolo_model(image_path, save=True)\n",
    "    patches = []\n",
    "    ys = []\n",
    "    for box in sorted(results[0].boxes, key=lambda x: x.xywh[0][1]):\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        x_center, y_center, w, h  = box.xywh[0].cpu().numpy()\n",
    "        x, y = x_center - w / 2, y_center - h / 2\n",
    "        cropped_image = image.crop((x, y, x + w, y + h))\n",
    "        patches.append(cropped_image)\n",
    "        ys.append(y)\n",
    "    bounding_box_path = results[0].save_dir + results[0].path[results[0].path.rindex('/'):-4] + '.jpg'\n",
    "    return patches, ys, bounding_box_path\n",
    "\n",
    "def get_model_output(images):\n",
    "    pixel_values = processor(images=images, return_tensors=\"pt\").pixel_values.to(device)\n",
    "    output = trocr_model.generate(pixel_values, return_dict_in_generate=True, output_logits=True, max_new_tokens=30)\n",
    "    generated_texts = processor.batch_decode(output.sequences, skip_special_tokens=True)\n",
    "    return generated_texts, output.logits\n",
    "\n",
    "\n",
    "image_path = \"data/FML_whiteboard2.png\"\n",
    "cropped_images, y, bounding_box_path = get_cropped_images(image_path)\n",
    "generated_texts, logits = get_model_output(cropped_images)\n",
    "for i in range(len(generated_texts)):\n",
    "    print(generated_texts[i], logits[i].softmax(-1).max(-1).values.mean())"
   ],
   "id": "5d394c6596881fc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /Users/amaljoe/Desktop/Workspace/IITB/NLP/OCR_with_LLMs/data/FML_whiteboard2.png: 384x640 8 handwritten_lines, 39.2ms\n",
      "Speed: 3.6ms preprocess, 39.2ms inference, 10.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001B[1m/Users/amaljoe/Desktop/Workspace/IITB/NLP/OCR_with_LLMs/runs/detect/predict34\u001B[0m\n",
      "K-means clustering algorithm tensor(0.8210, device='mps:0')\n",
      "Assume we have K clusters of points ; each point in a cluster . tensor(0.9846, device='mps:0')\n",
      "Assume we have K clusters of points ; each point in a cluster . tensor(0.9086, device='mps:0')\n",
      "is closest to its centroid ( more than any other cluster centroid ) tensor(0.9713, device='mps:0')\n",
      "If cluster assignment is known , it is easy to compute the centriots . tensor(0.8718, device='mps:0')\n",
      "It cluster assignment is known , it is easy to compute the centroids . tensor(0.9372, device='mps:0')\n",
      "If cluster centrids are known , it is easy to do cluster assignment . tensor(0.9796, device='mps:0')\n",
      "How do we solve this chicken-egg problem ? Fix one , optimize the other ! tensor(0.9559, device='mps:0')\n"
     ]
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T09:24:15.002355Z",
     "start_time": "2024-11-26T09:24:14.887449Z"
    }
   },
   "cell_type": "code",
   "source": [
    "stacked_logits = torch.stack(logits, dim=1)\n",
    "processor.batch_decode([stacked_logits[-2].argmax(-1)[:5]], skip_special_tokens=True)"
   ],
   "id": "9539651d8f9a9e22",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['If cluster centrids']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T09:17:50.578637Z",
     "start_time": "2024-11-26T09:17:50.502586Z"
    }
   },
   "cell_type": "code",
   "source": "stacked_logits[-2].softmax(-1).max(-1)",
   "id": "4bab4daee1ab1cba",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([0.5884, 0.9979, 0.3797, 0.8033, 0.7809, 1.0000, 1.0000, 0.9999, 0.9997, 1.0000, 0.9999, 0.9966, 0.9997, 0.2181, 0.9184, 0.6810, 0.9987, 0.9935, 0.9677], device='mps:0'),\n",
       "indices=tensor([ 1106, 18016,   715,   338,  7823,    32,   684,  2156,    24,    16,  1365,     7,   109, 18016, 11717,   479,     2,     2,     2], device='mps:0'))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T09:31:41.810563Z",
     "start_time": "2024-11-26T09:31:41.626104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "res = unmasker_large(\"\"\"K Means clustering algorithm\n",
    "Assume we have K cluster of <mask>; each point in a cluster\n",
    "Is closest to its centroid (more than any other cluster centroid)\n",
    "If cluster assignment is known, it is easy to compute the centroid\n",
    "If cluster <mask> is known, it is easy to do cluster assignment\"\"\")\n",
    "res"
   ],
   "id": "e9bceaa80177d260",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'score': 0.8517557978630066,\n",
       "   'token': 332,\n",
       "   'token_str': ' points',\n",
       "   'sequence': '<s>K Means clustering algorithm\\nAssume we have K cluster of points; each point in a cluster\\nIs closest to its centroid (more than any other cluster centroid)\\nIf cluster assignment is known, it is easy to compute the centroid\\nIf cluster<mask> is known, it is easy to do cluster assignment</s>'},\n",
       "  {'score': 0.0489627867937088,\n",
       "   'token': 32833,\n",
       "   'token_str': ' nodes',\n",
       "   'sequence': '<s>K Means clustering algorithm\\nAssume we have K cluster of nodes; each point in a cluster\\nIs closest to its centroid (more than any other cluster centroid)\\nIf cluster assignment is known, it is easy to compute the centroid\\nIf cluster<mask> is known, it is easy to do cluster assignment</s>'},\n",
       "  {'score': 0.01644345372915268,\n",
       "   'token': 8720,\n",
       "   'token_str': ' objects',\n",
       "   'sequence': '<s>K Means clustering algorithm\\nAssume we have K cluster of objects; each point in a cluster\\nIs closest to its centroid (more than any other cluster centroid)\\nIf cluster assignment is known, it is easy to compute the centroid\\nIf cluster<mask> is known, it is easy to do cluster assignment</s>'},\n",
       "  {'score': 0.010072370059788227,\n",
       "   'token': 414,\n",
       "   'token_str': ' data',\n",
       "   'sequence': '<s>K Means clustering algorithm\\nAssume we have K cluster of data; each point in a cluster\\nIs closest to its centroid (more than any other cluster centroid)\\nIf cluster assignment is known, it is easy to compute the centroid\\nIf cluster<mask> is known, it is easy to do cluster assignment</s>'},\n",
       "  {'score': 0.008560090325772762,\n",
       "   'token': 477,\n",
       "   'token_str': ' point',\n",
       "   'sequence': '<s>K Means clustering algorithm\\nAssume we have K cluster of point; each point in a cluster\\nIs closest to its centroid (more than any other cluster centroid)\\nIf cluster assignment is known, it is easy to compute the centroid\\nIf cluster<mask> is known, it is easy to do cluster assignment</s>'}],\n",
       " [{'score': 0.6802806854248047,\n",
       "   'token': 11717,\n",
       "   'token_str': ' assignment',\n",
       "   'sequence': '<s>K Means clustering algorithm\\nAssume we have K cluster of<mask>; each point in a cluster\\nIs closest to its centroid (more than any other cluster centroid)\\nIf cluster assignment is known, it is easy to compute the centroid\\nIf cluster assignment is known, it is easy to do cluster assignment</s>'},\n",
       "  {'score': 0.02800857275724411,\n",
       "   'token': 22432,\n",
       "   'token_str': ' alignment',\n",
       "   'sequence': '<s>K Means clustering algorithm\\nAssume we have K cluster of<mask>; each point in a cluster\\nIs closest to its centroid (more than any other cluster centroid)\\nIf cluster assignment is known, it is easy to compute the centroid\\nIf cluster alignment is known, it is easy to do cluster assignment</s>'},\n",
       "  {'score': 0.019997363910079002,\n",
       "   'token': 3599,\n",
       "   'token_str': ' identity',\n",
       "   'sequence': '<s>K Means clustering algorithm\\nAssume we have K cluster of<mask>; each point in a cluster\\nIs closest to its centroid (more than any other cluster centroid)\\nIf cluster assignment is known, it is easy to compute the centroid\\nIf cluster identity is known, it is easy to do cluster assignment</s>'},\n",
       "  {'score': 0.017055394127964973,\n",
       "   'token': 15229,\n",
       "   'token_str': ' composition',\n",
       "   'sequence': '<s>K Means clustering algorithm\\nAssume we have K cluster of<mask>; each point in a cluster\\nIs closest to its centroid (more than any other cluster centroid)\\nIf cluster assignment is known, it is easy to compute the centroid\\nIf cluster composition is known, it is easy to do cluster assignment</s>'},\n",
       "  {'score': 0.013458051718771458,\n",
       "   'token': 1836,\n",
       "   'token_str': ' size',\n",
       "   'sequence': '<s>K Means clustering algorithm\\nAssume we have K cluster of<mask>; each point in a cluster\\nIs closest to its centroid (more than any other cluster centroid)\\nIf cluster assignment is known, it is easy to compute the centroid\\nIf cluster size is known, it is easy to do cluster assignment</s>'}]]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T09:28:06.381682Z",
     "start_time": "2024-11-26T09:28:06.379163Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f1845790b97c90f0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.10382635146379471,\n",
       "  'token': 17194,\n",
       "  'token_str': ' algorithm',\n",
       "  'sequence': '<s>K Means clustering algorithm\\nAssume we have K cluster of points; each point in a cluster\\nIs closest to its centroid (more than any other cluster centroid)\\nIf cluster assignment is known, it is easy to compute the centroid\\nIf cluster<mask><mask> algorithm is known, it is easy to do cluster assignment</s>'},\n",
       " {'score': 0.03082429990172386,\n",
       "  'token': 5043,\n",
       "  'token_str': ' function',\n",
       "  'sequence': '<s>K Means clustering algorithm\\nAssume we have K cluster of points; each point in a cluster\\nIs closest to its centroid (more than any other cluster centroid)\\nIf cluster assignment is known, it is easy to compute the centroid\\nIf cluster<mask><mask> function is known, it is easy to do cluster assignment</s>'},\n",
       " {'score': 0.017390219494700432,\n",
       "  'token': 3854,\n",
       "  'token_str': ' distribution',\n",
       "  'sequence': '<s>K Means clustering algorithm\\nAssume we have K cluster of points; each point in a cluster\\nIs closest to its centroid (more than any other cluster centroid)\\nIf cluster assignment is known, it is easy to compute the centroid\\nIf cluster<mask><mask> distribution is known, it is easy to do cluster assignment</s>'},\n",
       " {'score': 0.016082465648651123,\n",
       "  'token': 40899,\n",
       "  'token_str': 'ometry',\n",
       "  'sequence': '<s>K Means clustering algorithm\\nAssume we have K cluster of points; each point in a cluster\\nIs closest to its centroid (more than any other cluster centroid)\\nIf cluster assignment is known, it is easy to compute the centroid\\nIf cluster<mask><mask>ometry is known, it is easy to do cluster assignment</s>'},\n",
       " {'score': 0.014248057268559933,\n",
       "  'token': 1825,\n",
       "  'token_str': 'ness',\n",
       "  'sequence': '<s>K Means clustering algorithm\\nAssume we have K cluster of points; each point in a cluster\\nIs closest to its centroid (more than any other cluster centroid)\\nIf cluster assignment is known, it is easy to compute the centroid\\nIf cluster<mask><mask>ness is known, it is easy to do cluster assignment</s>'}]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 100
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
